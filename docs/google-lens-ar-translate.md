# 谷歌镜头的实时翻译将很快看起来更加无缝

> 原文：<https://www.xda-developers.com/google-lens-ar-translate/>

在今天的年度搜索活动上，谷歌谈到了今年晚些时候谷歌搜索的几个新功能。此外，该公司还展示了谷歌镜头的一项新功能，该功能利用机器学习和增强现实技术来提供更加无缝的实时翻译体验。

Google Lens 支持实时翻译已经有一段时间了。然而，在目前的状态下，该功能会覆盖原始图像以显示翻译后的文本，使其外观很难看。随着谷歌镜头 AR 翻译体验的更新，谷歌旨在使实时翻译看起来更加自然和无缝。

正如你在附图中看到的，新的镜头 AR Translate 体验没有在原始图像上显示任何难看的线条。这是因为它利用机器学习来删除原始文本，用人工智能生成的背景重建下面的像素，然后将翻译的文本覆盖在上面。最终的图像看起来更加无缝。

虽然这种新体验似乎会降低谷歌镜头的实时翻译速度，但谷歌向我们保证不会。该公司声称，该功能使用优化的机器学习模型来擦除原文，重建背景，并在短短 100 毫秒内覆盖翻译的文本。谷歌使用生成性对抗网络(又名 GAN 模型)来实现这一壮举，这与为像素设备上的魔法橡皮擦功能提供动力的技术相同。

遗憾的是，你将不得不等待一段时间来尝试新的镜头 AR 翻译体验。谷歌表示，这种体验将在今年晚些时候向用户推出，但该公司尚未提供明确的发布时间表。目前，还不清楚新的体验是否会在所有平台的 Google Lens 上提供。

*你觉得新的镜头 AR 翻译体验怎么样？你期待尝试一下吗？请在下面的评论区告诉我们。*